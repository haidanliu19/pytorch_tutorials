{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PYTORCH로 딥러닝하기 60분만에 끝장내기_예제로 배우는 파이토치(PYTORCH)_PYTORCH: NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PYTORCH로 딥러닝하기 60분만에 끝장내기"
      ],
      "metadata": {
        "id": "5sA6XdY2yD_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "y=sin(x) 을 예측할 수 있도록, -\\pi−π 부터 pipi 까지 유클리드 거리(Euclidean distance)를 최소화하도록 3차 다항식을 학습합니다.\n",
        "\n",
        "이번에는 PyTorch의 nn 패키지를 사용하여 신경망을 구현하겠습니다. PyTorch autograd는 연산 그래프를 정의하고 변화도를 계산하는 것을 손쉽게 만들어주지만, autograd 그 자체만으로는 복잡한 신경망을 정의하기에는 너무 저수준(low-level)일 수 있습니다; 이것이 nn 패키지가 필요한 이유입니다. nn 패키지는 입력으로부터 출력을 생성하고 학습 가능한 가중치를 갖는 신경망 계층(layer) 같은 Module의 집합을 정의합니다."
      ],
      "metadata": {
        "id": "kPZ8agYqmij8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "p = torch.tensor([1, 2, 3])\n",
        "xx = x.unsqueeze(-1).pow(p)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        ")\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad\n",
        "\n",
        "linear_layer = model[0]\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nbnwEfaiHr2",
        "outputId": "029bec0b-911f-454d-a2a7-90ef96e77e3b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 616.1405029296875\n",
            "199 417.1893310546875\n",
            "299 283.65081787109375\n",
            "399 193.9459991455078\n",
            "499 133.63613891601562\n",
            "599 93.05391693115234\n",
            "699 65.72183227539062\n",
            "799 47.2967529296875\n",
            "899 34.86423873901367\n",
            "999 26.4671573638916\n",
            "1099 20.789966583251953\n",
            "1199 16.947647094726562\n",
            "1299 14.344526290893555\n",
            "1399 12.579061508178711\n",
            "1499 11.380392074584961\n",
            "1599 10.56563949584961\n",
            "1699 10.011232376098633\n",
            "1799 9.633551597595215\n",
            "1899 9.37597370147705\n",
            "1999 9.200089454650879\n",
            "Result: y = -0.01514617633074522 + 0.8437654972076416 x + 0.0026129670441150665 x^2 + -0.09148475527763367 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fq8lJOs8muQk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}